[INFO ] [2023-02-09 16:50:09.411] [] [] [o.s.b.t.context.SpringBootTestContextBootstrapper] [305] -[Neither @ContextConfiguration nor @ContextHierarchy found for test class [com.kanke.ml.CorrelationTests], using SpringBootContextLoader]
[INFO ] [2023-02-09 16:50:09.419] [] [] [o.s.test.context.support.AbstractContextLoader] [264] -[Could not detect default resource locations for test class [com.kanke.ml.CorrelationTests]: no resource found for suffixes {-context.xml, Context.groovy}.]
[INFO ] [2023-02-09 16:50:09.420] [] [] [o.s.t.c.support.AnnotationConfigContextLoaderUtils] [83] -[Could not detect default configuration classes for test class [com.kanke.ml.CorrelationTests]: CorrelationTests does not declare any static, non-private, non-final, nested classes annotated with @Configuration.]
[INFO ] [2023-02-09 16:50:09.555] [] [] [o.s.b.t.context.SpringBootTestContextBootstrapper] [238] -[Found @SpringBootConfiguration com.kanke.ml.MlApplication for test class com.kanke.ml.CorrelationTests]
[INFO ] [2023-02-09 16:50:09.691] [] [] [o.s.b.t.context.SpringBootTestContextBootstrapper] [245] -[Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener, org.springframework.boot.test.autoconfigure.webservices.client.MockWebServiceServerTestExecutionListener, org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.event.ApplicationEventsTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener, org.springframework.test.context.event.EventPublishingTestExecutionListener]]
[INFO ] [2023-02-09 16:50:09.711] [] [] [o.s.b.t.context.SpringBootTestContextBootstrapper] [174] -[Using TestExecutionListeners: [org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@73302995, org.springframework.test.context.event.ApplicationEventsTestExecutionListener@1838ccb8, org.springframework.boot.test.mock.mockito.MockitoTestExecutionListener@6c2ed0cd, org.springframework.boot.test.autoconfigure.SpringBootDependencyInjectionTestExecutionListener@7d9e8ef7, org.springframework.test.context.support.DirtiesContextTestExecutionListener@f107c50, org.springframework.test.context.event.EventPublishingTestExecutionListener@51133c06, org.springframework.boot.test.mock.mockito.ResetMocksTestExecutionListener@4b213651, org.springframework.boot.test.autoconfigure.restdocs.RestDocsTestExecutionListener@4241e0f4, org.springframework.boot.test.autoconfigure.web.client.MockRestServiceServerResetTestExecutionListener@4ebff610, org.springframework.boot.test.autoconfigure.web.servlet.MockMvcPrintOnlyOnFailureTestExecutionListener@60410cd, org.springframework.boot.test.autoconfigure.web.servlet.WebDriverTestExecutionListener@44d52de2, org.springframework.boot.test.autoconfigure.webservices.client.MockWebServiceServerTestExecutionListener@95e33cc]]
[INFO ] [2023-02-09 16:50:10.055] [] [] [com.kanke.ml.CorrelationTests] [55] -[Starting CorrelationTests using Java 1.8.0_321 on coke with PID 154936 (started by cao in C:\Users\cao\Documents\GitHub\rec\spark-ml)]
[INFO ] [2023-02-09 16:50:10.056] [] [] [com.kanke.ml.CorrelationTests] [631] -[No active profile set, falling back to 1 default profile: "default"]
[INFO ] [2023-02-09 16:50:10.918] [] [] [com.kanke.ml.CorrelationTests] [61] -[Started CorrelationTests in 1.164 seconds (JVM running for 2.855)]
[INFO ] [2023-02-09 16:50:11.820] [] [] [org.apache.spark.SparkContext] [61] -[Running Spark version 3.3.0]
[INFO ] [2023-02-09 16:50:12.132] [] [] [org.apache.spark.resource.ResourceUtils] [61] -[==============================================================]
[INFO ] [2023-02-09 16:50:12.132] [] [] [org.apache.spark.resource.ResourceUtils] [61] -[No custom resources configured for spark.driver.]
[INFO ] [2023-02-09 16:50:12.133] [] [] [org.apache.spark.resource.ResourceUtils] [61] -[==============================================================]
[INFO ] [2023-02-09 16:50:12.133] [] [] [org.apache.spark.SparkContext] [61] -[Submitted application: als]
[INFO ] [2023-02-09 16:50:12.161] [] [] [org.apache.spark.resource.ResourceProfile] [61] -[Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)]
[INFO ] [2023-02-09 16:50:12.172] [] [] [org.apache.spark.resource.ResourceProfile] [61] -[Limiting resource is cpu]
[INFO ] [2023-02-09 16:50:12.173] [] [] [org.apache.spark.resource.ResourceProfileManager] [61] -[Added ResourceProfile id: 0]
[INFO ] [2023-02-09 16:50:12.250] [] [] [org.apache.spark.SecurityManager] [61] -[Changing view acls to: cao]
[INFO ] [2023-02-09 16:50:12.250] [] [] [org.apache.spark.SecurityManager] [61] -[Changing modify acls to: cao]
[INFO ] [2023-02-09 16:50:12.251] [] [] [org.apache.spark.SecurityManager] [61] -[Changing view acls groups to: ]
[INFO ] [2023-02-09 16:50:12.251] [] [] [org.apache.spark.SecurityManager] [61] -[Changing modify acls groups to: ]
[INFO ] [2023-02-09 16:50:12.252] [] [] [org.apache.spark.SecurityManager] [61] -[SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cao); groups with view permissions: Set(); users  with modify permissions: Set(cao); groups with modify permissions: Set()]
[INFO ] [2023-02-09 16:50:13.481] [] [] [org.apache.spark.util.Utils] [61] -[Successfully started service 'sparkDriver' on port 12655.]
[INFO ] [2023-02-09 16:50:13.520] [] [] [org.apache.spark.SparkEnv] [61] -[Registering MapOutputTracker]
[INFO ] [2023-02-09 16:50:13.570] [] [] [org.apache.spark.SparkEnv] [61] -[Registering BlockManagerMaster]
[INFO ] [2023-02-09 16:50:13.600] [] [] [o.apache.spark.storage.BlockManagerMasterEndpoint] [61] -[Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information]
[INFO ] [2023-02-09 16:50:13.601] [] [] [o.apache.spark.storage.BlockManagerMasterEndpoint] [61] -[BlockManagerMasterEndpoint up]
[INFO ] [2023-02-09 16:50:13.605] [] [] [org.apache.spark.SparkEnv] [61] -[Registering BlockManagerMasterHeartbeat]
[INFO ] [2023-02-09 16:50:13.644] [] [] [org.apache.spark.storage.DiskBlockManager] [61] -[Created local directory at C:\Users\cao\AppData\Local\Temp\blockmgr-b3f65307-249f-4a06-9070-dc381ec995f7]
[INFO ] [2023-02-09 16:50:13.683] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[MemoryStore started with capacity 1712.4 MiB]
[INFO ] [2023-02-09 16:50:13.706] [] [] [org.apache.spark.SparkEnv] [61] -[Registering OutputCommitCoordinator]
[INFO ] [2023-02-09 16:50:13.825] [] [] [org.sparkproject.jetty.util.log] [170] -[Logging initialized @5761ms to org.sparkproject.jetty.util.log.Slf4jLog]
[INFO ] [2023-02-09 16:50:13.974] [] [] [org.sparkproject.jetty.server.Server] [375] -[jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 1.8.0_321-b07]
[INFO ] [2023-02-09 16:50:14.000] [] [] [org.sparkproject.jetty.server.Server] [415] -[Started @5938ms]
[INFO ] [2023-02-09 16:50:14.061] [] [] [org.sparkproject.jetty.server.AbstractConnector] [333] -[Started ServerConnector@5ae15{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}]
[INFO ] [2023-02-09 16:50:14.062] [] [] [org.apache.spark.util.Utils] [61] -[Successfully started service 'SparkUI' on port 4040.]
[INFO ] [2023-02-09 16:50:14.089] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@5c6a5192{/,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.226] [] [] [org.apache.spark.executor.Executor] [61] -[Starting executor ID driver on host coke]
[INFO ] [2023-02-09 16:50:14.238] [] [] [org.apache.spark.executor.Executor] [61] -[Starting executor with user classpath (userClassPathFirst = false): '']
[INFO ] [2023-02-09 16:50:14.274] [] [] [org.apache.spark.util.Utils] [61] -[Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 12678.]
[INFO ] [2023-02-09 16:50:14.274] [] [] [o.a.spark.network.netty.NettyBlockTransferService] [82] -[Server created on coke:12678]
[INFO ] [2023-02-09 16:50:14.277] [] [] [org.apache.spark.storage.BlockManager] [61] -[Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy]
[INFO ] [2023-02-09 16:50:14.287] [] [] [org.apache.spark.storage.BlockManagerMaster] [61] -[Registering BlockManager BlockManagerId(driver, coke, 12678, None)]
[INFO ] [2023-02-09 16:50:14.292] [] [] [o.apache.spark.storage.BlockManagerMasterEndpoint] [61] -[Registering block manager coke:12678 with 1712.4 MiB RAM, BlockManagerId(driver, coke, 12678, None)]
[INFO ] [2023-02-09 16:50:14.294] [] [] [org.apache.spark.storage.BlockManagerMaster] [61] -[Registered BlockManager BlockManagerId(driver, coke, 12678, None)]
[INFO ] [2023-02-09 16:50:14.296] [] [] [org.apache.spark.storage.BlockManager] [61] -[Initialized BlockManager: BlockManagerId(driver, coke, 12678, None)]
[INFO ] [2023-02-09 16:50:14.543] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [1159] -[Stopped o.s.j.s.ServletContextHandler@5c6a5192{/,null,STOPPED,@Spark}]
[INFO ] [2023-02-09 16:50:14.544] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@4be490da{/jobs,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.545] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@353e6389{/jobs/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.546] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@7c950b3b{/jobs/job,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.547] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@6806468e{/jobs/job/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.548] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@68631b1d{/stages,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.548] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@a0c5be{/stages/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.550] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@e62319f{/stages/stage,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.551] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@24a0c58b{/stages/stage/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.552] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@7f3c0399{/stages/pool,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.552] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@3a11c0eb{/stages/pool/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.553] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@2c2c3947{/storage,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.554] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@7ec08115{/storage/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.555] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@1e76afeb{/storage/rdd,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.556] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@3e4d40ea{/storage/rdd/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.556] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@2c9d90fc{/environment,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.557] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@418f890f{/environment/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.558] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@7d66e544{/executors,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.559] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@5b1c32e4{/executors/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.560] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@48bc2fce{/executors/threadDump,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.562] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@24fba488{/executors/threadDump/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.571] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@5a4d4f9c{/static,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.573] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@634f58d2{/,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.573] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@7b18658a{/api,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.574] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@281b2dfd{/jobs/job/kill,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.575] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@1cd2143b{/stages/stage/kill,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:14.579] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@611d0763{/metrics/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:16.274] [] [] [org.apache.spark.sql.internal.SharedState] [61] -[Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.]
[INFO ] [2023-02-09 16:50:16.285] [] [] [org.apache.spark.sql.internal.SharedState] [61] -[Warehouse path is 'file:/C:/Users/cao/Documents/GitHub/rec/spark-ml/spark-warehouse'.]
[INFO ] [2023-02-09 16:50:16.303] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@4cd5fc46{/SQL,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:16.304] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@3221588e{/SQL/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:16.305] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@7c8df667{/SQL/execution,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:16.306] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@be616f0{/SQL/execution/json,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:16.319] [] [] [o.sparkproject.jetty.server.handler.ContextHandler] [921] -[Started o.s.j.s.ServletContextHandler@70697478{/static/sql,null,AVAILABLE,@Spark}]
[INFO ] [2023-02-09 16:50:17.721] [] [] [o.a.s.s.catalyst.expressions.codegen.CodeGenerator] [61] -[Code generated in 324.9431 ms]
[INFO ] [2023-02-09 16:50:19.212] [] [] [o.a.s.s.catalyst.expressions.codegen.CodeGenerator] [61] -[Code generated in 17.5437 ms]
[INFO ] [2023-02-09 16:50:19.490] [] [] [org.apache.spark.SparkContext] [61] -[Starting job: first at RowMatrix.scala:62]
[INFO ] [2023-02-09 16:50:19.514] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Got job 0 (first at RowMatrix.scala:62) with 1 output partitions]
[INFO ] [2023-02-09 16:50:19.514] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Final stage: ResultStage 0 (first at RowMatrix.scala:62)]
[INFO ] [2023-02-09 16:50:19.515] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Parents of final stage: List()]
[INFO ] [2023-02-09 16:50:19.517] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Missing parents: List()]
[INFO ] [2023-02-09 16:50:19.522] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ResultStage 0 (MapPartitionsRDD[5] at map at Correlation.scala:68), which has no missing parents]
[INFO ] [2023-02-09 16:50:19.592] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_0 stored as values in memory (estimated size 18.5 KiB, free 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:19.672] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:19.675] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_0_piece0 in memory on coke:12678 (size: 8.6 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:19.678] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 0 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:19.691] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at Correlation.scala:68) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:19.692] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 0.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:19.770] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 0.0 (TID 0) (coke, executor driver, partition 0, PROCESS_LOCAL, 5120 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:19.787] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 0.0 (TID 0)]
[INFO ] [2023-02-09 16:50:20.072] [] [] [o.a.s.s.catalyst.expressions.codegen.CodeGenerator] [61] -[Code generated in 12.6142 ms]
[INFO ] [2023-02-09 16:50:20.098] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 0.0 (TID 0). 1386 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:20.106] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 0.0 (TID 0) in 353 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:20.108] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 0.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:20.114] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ResultStage 0 (first at RowMatrix.scala:62) finished in 0.574 s]
[INFO ] [2023-02-09 16:50:20.117] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 0 is finished. Cancelling potential speculative or zombie tasks for this job]
[INFO ] [2023-02-09 16:50:20.117] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Killing all running tasks in stage 0: Stage finished]
[INFO ] [2023-02-09 16:50:20.118] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 0 finished: first at RowMatrix.scala:62, took 0.628001 s]
[INFO ] [2023-02-09 16:50:20.169] [] [] [org.apache.spark.SparkContext] [61] -[Starting job: treeAggregate at Statistics.scala:58]
[INFO ] [2023-02-09 16:50:20.170] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Got job 1 (treeAggregate at Statistics.scala:58) with 1 output partitions]
[INFO ] [2023-02-09 16:50:20.170] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Final stage: ResultStage 1 (treeAggregate at Statistics.scala:58)]
[INFO ] [2023-02-09 16:50:20.170] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Parents of final stage: List()]
[INFO ] [2023-02-09 16:50:20.171] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Missing parents: List()]
[INFO ] [2023-02-09 16:50:20.172] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ResultStage 1 (MapPartitionsRDD[7] at treeAggregate at Statistics.scala:58), which has no missing parents]
[INFO ] [2023-02-09 16:50:20.176] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_1 stored as values in memory (estimated size 20.5 KiB, free 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:20.178] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:20.179] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_1_piece0 in memory on coke:12678 (size: 9.4 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:20.179] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 1 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:20.180] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:20.180] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 1.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:20.182] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 1.0 (TID 1) (coke, executor driver, partition 0, PROCESS_LOCAL, 5120 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:20.182] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 1.0 (TID 1)]
[INFO ] [2023-02-09 16:50:20.216] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 1.0 (TID 1). 1931 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:20.217] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 1.0 (TID 1) in 36 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:20.217] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 1.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:20.218] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ResultStage 1 (treeAggregate at Statistics.scala:58) finished in 0.045 s]
[INFO ] [2023-02-09 16:50:20.218] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 1 is finished. Cancelling potential speculative or zombie tasks for this job]
[INFO ] [2023-02-09 16:50:20.218] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Killing all running tasks in stage 1: Stage finished]
[INFO ] [2023-02-09 16:50:20.219] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 1 finished: treeAggregate at Statistics.scala:58, took 0.049482 s]
[INFO ] [2023-02-09 16:50:20.236] [] [] [org.apache.spark.SparkContext] [61] -[Starting job: isEmpty at RowMatrix.scala:441]
[INFO ] [2023-02-09 16:50:20.238] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Got job 2 (isEmpty at RowMatrix.scala:441) with 1 output partitions]
[INFO ] [2023-02-09 16:50:20.238] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Final stage: ResultStage 2 (isEmpty at RowMatrix.scala:441)]
[INFO ] [2023-02-09 16:50:20.238] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Parents of final stage: List()]
[INFO ] [2023-02-09 16:50:20.239] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Missing parents: List()]
[INFO ] [2023-02-09 16:50:20.240] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ResultStage 2 (MapPartitionsRDD[8] at filter at RowMatrix.scala:441), which has no missing parents]
[INFO ] [2023-02-09 16:50:20.243] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_2 stored as values in memory (estimated size 18.9 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:20.246] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:20.247] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_2_piece0 in memory on coke:12678 (size: 8.8 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:20.247] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 2 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:20.248] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at filter at RowMatrix.scala:441) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:20.248] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 2.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:20.249] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 2.0 (TID 2) (coke, executor driver, partition 0, PROCESS_LOCAL, 5120 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:20.250] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 2.0 (TID 2)]
[INFO ] [2023-02-09 16:50:20.267] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 2.0 (TID 2). 1215 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:20.268] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 2.0 (TID 2) in 19 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:20.269] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 2.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:20.270] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ResultStage 2 (isEmpty at RowMatrix.scala:441) finished in 0.028 s]
[INFO ] [2023-02-09 16:50:20.271] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 2 is finished. Cancelling potential speculative or zombie tasks for this job]
[INFO ] [2023-02-09 16:50:20.271] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Killing all running tasks in stage 2: Stage finished]
[INFO ] [2023-02-09 16:50:20.271] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 2 finished: isEmpty at RowMatrix.scala:441, took 0.033795 s]
[INFO ] [2023-02-09 16:50:20.274] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_3 stored as values in memory (estimated size 88.0 B, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:20.276] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_3_piece0 stored as bytes in memory (estimated size 165.0 B, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:20.278] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_3_piece0 in memory on coke:12678 (size: 165.0 B, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:20.279] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 3 from broadcast at RowMatrix.scala:165]
[INFO ] [2023-02-09 16:50:20.310] [] [] [org.apache.spark.SparkContext] [61] -[Starting job: treeAggregate at RowMatrix.scala:171]
[INFO ] [2023-02-09 16:50:20.313] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Got job 3 (treeAggregate at RowMatrix.scala:171) with 1 output partitions]
[INFO ] [2023-02-09 16:50:20.313] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Final stage: ResultStage 3 (treeAggregate at RowMatrix.scala:171)]
[INFO ] [2023-02-09 16:50:20.313] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Parents of final stage: List()]
[INFO ] [2023-02-09 16:50:20.314] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Missing parents: List()]
[INFO ] [2023-02-09 16:50:20.316] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ResultStage 3 (MapPartitionsRDD[9] at treeAggregate at RowMatrix.scala:171), which has no missing parents]
[INFO ] [2023-02-09 16:50:20.382] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_4 stored as values in memory (estimated size 20.0 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:20.386] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:20.387] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_4_piece0 in memory on coke:12678 (size: 9.3 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:20.388] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 4 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:20.388] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at treeAggregate at RowMatrix.scala:171) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:20.389] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 3.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:20.390] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 3.0 (TID 3) (coke, executor driver, partition 0, PROCESS_LOCAL, 5120 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:20.391] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 3.0 (TID 3)]
[WARN ] [2023-02-09 16:50:20.911] [] [] [dev.ludovic.netlib.InstanceBuilder$NativeBLAS] [60] -[Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS]
[WARN ] [2023-02-09 16:50:20.914] [] [] [dev.ludovic.netlib.InstanceBuilder$NativeBLAS] [65] -[Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS]
[INFO ] [2023-02-09 16:50:20.927] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 3.0 (TID 3). 1298 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:20.929] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 3.0 (TID 3) in 539 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:20.929] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 3.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:20.929] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ResultStage 3 (treeAggregate at RowMatrix.scala:171) finished in 0.610 s]
[INFO ] [2023-02-09 16:50:20.929] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 3 is finished. Cancelling potential speculative or zombie tasks for this job]
[INFO ] [2023-02-09 16:50:20.929] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Killing all running tasks in stage 3: Stage finished]
[INFO ] [2023-02-09 16:50:20.929] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 3 finished: treeAggregate at RowMatrix.scala:171, took 0.618749 s]
[INFO ] [2023-02-09 16:50:20.931] [] [] [org.apache.spark.broadcast.TorrentBroadcast] [61] -[Destroying Broadcast(3) (from destroy at RowMatrix.scala:201)]
[INFO ] [2023-02-09 16:50:20.950] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Removed broadcast_3_piece0 on coke:12678 in memory (size: 165.0 B, free: 1712.4 MiB)]
[WARN ] [2023-02-09 16:50:21.318] [] [] [o.a.s.mllib.stat.correlation.PearsonCorrelation] [73] -[Pearson correlation matrix contains NaN values.]
[INFO ] [2023-02-09 16:50:21.398] [] [] [o.a.s.s.catalyst.expressions.codegen.CodeGenerator] [61] -[Code generated in 17.4667 ms]
[INFO ] [2023-02-09 16:50:21.411] [] [] [o.a.s.s.catalyst.expressions.codegen.CodeGenerator] [61] -[Code generated in 8.9522 ms]
[INFO ] [2023-02-09 16:50:21.567] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Removed broadcast_2_piece0 on coke:12678 in memory (size: 8.8 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.573] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Removed broadcast_1_piece0 on coke:12678 in memory (size: 9.4 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.580] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Removed broadcast_0_piece0 on coke:12678 in memory (size: 8.6 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.586] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Removed broadcast_4_piece0 on coke:12678 in memory (size: 9.3 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.586] [] [] [org.apache.spark.SparkContext] [61] -[Starting job: first at RowMatrix.scala:62]
[INFO ] [2023-02-09 16:50:21.615] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Registering RDD 17 (flatMap at SpearmanCorrelation.scala:48) as input to shuffle 1]
[INFO ] [2023-02-09 16:50:21.620] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Registering RDD 20 (mapPartitions at SpearmanCorrelation.scala:54) as input to shuffle 0]
[INFO ] [2023-02-09 16:50:21.621] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Got job 4 (first at RowMatrix.scala:62) with 1 output partitions]
[INFO ] [2023-02-09 16:50:21.621] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Final stage: ResultStage 6 (first at RowMatrix.scala:62)]
[INFO ] [2023-02-09 16:50:21.621] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Parents of final stage: List(ShuffleMapStage 5)]
[INFO ] [2023-02-09 16:50:21.622] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Missing parents: List(ShuffleMapStage 5)]
[INFO ] [2023-02-09 16:50:21.626] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at flatMap at SpearmanCorrelation.scala:48), which has no missing parents]
[INFO ] [2023-02-09 16:50:21.638] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_5 stored as values in memory (estimated size 20.4 KiB, free 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.643] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.646] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_5_piece0 in memory on coke:12678 (size: 9.6 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.647] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 5 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:21.649] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at flatMap at SpearmanCorrelation.scala:48) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:21.649] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 4.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:21.652] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 4.0 (TID 4) (coke, executor driver, partition 0, PROCESS_LOCAL, 5109 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:21.653] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 4.0 (TID 4)]
[INFO ] [2023-02-09 16:50:21.745] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 4.0 (TID 4). 1341 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:21.747] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 4.0 (TID 4) in 97 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:21.748] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 4.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:21.750] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ShuffleMapStage 4 (flatMap at SpearmanCorrelation.scala:48) finished in 0.121 s]
[INFO ] [2023-02-09 16:50:21.751] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[looking for newly runnable stages]
[INFO ] [2023-02-09 16:50:21.751] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[running: Set()]
[INFO ] [2023-02-09 16:50:21.751] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[waiting: Set(ShuffleMapStage 5, ResultStage 6)]
[INFO ] [2023-02-09 16:50:21.752] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[failed: Set()]
[INFO ] [2023-02-09 16:50:21.755] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at mapPartitions at SpearmanCorrelation.scala:54), which has no missing parents]
[INFO ] [2023-02-09 16:50:21.765] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_6 stored as values in memory (estimated size 6.6 KiB, free 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.768] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.770] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_6_piece0 in memory on coke:12678 (size: 3.6 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.771] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 6 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:21.772] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at mapPartitions at SpearmanCorrelation.scala:54) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:21.772] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 5.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:21.778] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 5.0 (TID 5) (coke, executor driver, partition 0, NODE_LOCAL, 4370 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:21.779] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 5.0 (TID 5)]
[INFO ] [2023-02-09 16:50:21.857] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Getting 1 (445.0 B) non-empty blocks including 1 (445.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks]
[INFO ] [2023-02-09 16:50:21.861] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Started 0 remote fetches in 15 ms]
[INFO ] [2023-02-09 16:50:21.926] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 5.0 (TID 5). 1462 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:21.927] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 5.0 (TID 5) in 151 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:21.927] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 5.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:21.928] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ShuffleMapStage 5 (mapPartitions at SpearmanCorrelation.scala:54) finished in 0.165 s]
[INFO ] [2023-02-09 16:50:21.928] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[looking for newly runnable stages]
[INFO ] [2023-02-09 16:50:21.929] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[running: Set()]
[INFO ] [2023-02-09 16:50:21.929] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[waiting: Set(ResultStage 6)]
[INFO ] [2023-02-09 16:50:21.929] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[failed: Set()]
[INFO ] [2023-02-09 16:50:21.929] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ResultStage 6 (MapPartitionsRDD[22] at map at SpearmanCorrelation.scala:84), which has no missing parents]
[INFO ] [2023-02-09 16:50:21.933] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_7 stored as values in memory (estimated size 7.7 KiB, free 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.936] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.0 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:21.938] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_7_piece0 in memory on coke:12678 (size: 4.0 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:21.938] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 7 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:21.939] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[22] at map at SpearmanCorrelation.scala:84) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:21.939] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 6.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:21.941] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 6.0 (TID 6) (coke, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:21.941] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 6.0 (TID 6)]
[INFO ] [2023-02-09 16:50:21.946] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks]
[INFO ] [2023-02-09 16:50:21.946] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Started 0 remote fetches in 0 ms]
[INFO ] [2023-02-09 16:50:21.965] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 6.0 (TID 6). 1422 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:21.967] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 6.0 (TID 6) in 27 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:21.967] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 6.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:21.968] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ResultStage 6 (first at RowMatrix.scala:62) finished in 0.037 s]
[INFO ] [2023-02-09 16:50:21.968] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 4 is finished. Cancelling potential speculative or zombie tasks for this job]
[INFO ] [2023-02-09 16:50:21.968] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Killing all running tasks in stage 6: Stage finished]
[INFO ] [2023-02-09 16:50:21.969] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 4 finished: first at RowMatrix.scala:62, took 0.382568 s]
[INFO ] [2023-02-09 16:50:21.986] [] [] [org.apache.spark.SparkContext] [61] -[Starting job: treeAggregate at Statistics.scala:58]
[INFO ] [2023-02-09 16:50:21.989] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Got job 5 (treeAggregate at Statistics.scala:58) with 1 output partitions]
[INFO ] [2023-02-09 16:50:21.989] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Final stage: ResultStage 9 (treeAggregate at Statistics.scala:58)]
[INFO ] [2023-02-09 16:50:21.989] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Parents of final stage: List(ShuffleMapStage 8)]
[INFO ] [2023-02-09 16:50:21.990] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Missing parents: List()]
[INFO ] [2023-02-09 16:50:21.991] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ResultStage 9 (MapPartitionsRDD[24] at treeAggregate at Statistics.scala:58), which has no missing parents]
[INFO ] [2023-02-09 16:50:21.996] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_8 stored as values in memory (estimated size 9.7 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:21.999] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:22.000] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_8_piece0 in memory on coke:12678 (size: 4.8 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:22.001] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 8 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:22.001] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[24] at treeAggregate at Statistics.scala:58) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:22.002] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 9.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:22.004] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 9.0 (TID 7) (coke, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:22.005] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 9.0 (TID 7)]
[INFO ] [2023-02-09 16:50:22.010] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks]
[INFO ] [2023-02-09 16:50:22.011] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Started 0 remote fetches in 1 ms]
[INFO ] [2023-02-09 16:50:22.018] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 9.0 (TID 7). 2052 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:22.019] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 9.0 (TID 7) in 16 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:22.020] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 9.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:22.021] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ResultStage 9 (treeAggregate at Statistics.scala:58) finished in 0.028 s]
[INFO ] [2023-02-09 16:50:22.021] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 5 is finished. Cancelling potential speculative or zombie tasks for this job]
[INFO ] [2023-02-09 16:50:22.021] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Killing all running tasks in stage 9: Stage finished]
[INFO ] [2023-02-09 16:50:22.022] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 5 finished: treeAggregate at Statistics.scala:58, took 0.035058 s]
[INFO ] [2023-02-09 16:50:22.037] [] [] [org.apache.spark.SparkContext] [61] -[Starting job: isEmpty at RowMatrix.scala:441]
[INFO ] [2023-02-09 16:50:22.040] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Got job 6 (isEmpty at RowMatrix.scala:441) with 1 output partitions]
[INFO ] [2023-02-09 16:50:22.041] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Final stage: ResultStage 12 (isEmpty at RowMatrix.scala:441)]
[INFO ] [2023-02-09 16:50:22.041] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Parents of final stage: List(ShuffleMapStage 11)]
[INFO ] [2023-02-09 16:50:22.041] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Missing parents: List()]
[INFO ] [2023-02-09 16:50:22.043] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ResultStage 12 (MapPartitionsRDD[25] at filter at RowMatrix.scala:441), which has no missing parents]
[INFO ] [2023-02-09 16:50:22.047] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_9 stored as values in memory (estimated size 8.1 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:22.049] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:22.052] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_9_piece0 in memory on coke:12678 (size: 4.2 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:22.052] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 9 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:22.053] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[25] at filter at RowMatrix.scala:441) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:22.053] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 12.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:22.054] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 12.0 (TID 8) (coke, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:22.055] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 12.0 (TID 8)]
[INFO ] [2023-02-09 16:50:22.059] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks]
[INFO ] [2023-02-09 16:50:22.060] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Started 0 remote fetches in 1 ms]
[INFO ] [2023-02-09 16:50:22.065] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 12.0 (TID 8). 1336 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:22.066] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 12.0 (TID 8) in 12 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:22.066] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 12.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:22.067] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ResultStage 12 (isEmpty at RowMatrix.scala:441) finished in 0.022 s]
[INFO ] [2023-02-09 16:50:22.067] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 6 is finished. Cancelling potential speculative or zombie tasks for this job]
[INFO ] [2023-02-09 16:50:22.067] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Killing all running tasks in stage 12: Stage finished]
[INFO ] [2023-02-09 16:50:22.067] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 6 finished: isEmpty at RowMatrix.scala:441, took 0.029611 s]
[INFO ] [2023-02-09 16:50:22.070] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_10 stored as values in memory (estimated size 88.0 B, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:22.073] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_10_piece0 stored as bytes in memory (estimated size 167.0 B, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:22.075] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_10_piece0 in memory on coke:12678 (size: 167.0 B, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:22.076] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 10 from broadcast at RowMatrix.scala:165]
[INFO ] [2023-02-09 16:50:22.088] [] [] [org.apache.spark.SparkContext] [61] -[Starting job: treeAggregate at RowMatrix.scala:171]
[INFO ] [2023-02-09 16:50:22.090] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Got job 7 (treeAggregate at RowMatrix.scala:171) with 1 output partitions]
[INFO ] [2023-02-09 16:50:22.090] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Final stage: ResultStage 15 (treeAggregate at RowMatrix.scala:171)]
[INFO ] [2023-02-09 16:50:22.090] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Parents of final stage: List(ShuffleMapStage 14)]
[INFO ] [2023-02-09 16:50:22.091] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Missing parents: List()]
[INFO ] [2023-02-09 16:50:22.092] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting ResultStage 15 (MapPartitionsRDD[26] at treeAggregate at RowMatrix.scala:171), which has no missing parents]
[INFO ] [2023-02-09 16:50:22.095] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_11 stored as values in memory (estimated size 9.3 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:22.098] [] [] [org.apache.spark.storage.memory.MemoryStore] [61] -[Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 1712.3 MiB)]
[INFO ] [2023-02-09 16:50:22.099] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Added broadcast_11_piece0 in memory on coke:12678 (size: 4.7 KiB, free: 1712.4 MiB)]
[INFO ] [2023-02-09 16:50:22.099] [] [] [org.apache.spark.SparkContext] [61] -[Created broadcast 11 from broadcast at DAGScheduler.scala:1513]
[INFO ] [2023-02-09 16:50:22.100] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[26] at treeAggregate at RowMatrix.scala:171) (first 15 tasks are for partitions Vector(0))]
[INFO ] [2023-02-09 16:50:22.100] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Adding task set 15.0 with 1 tasks resource profile 0]
[INFO ] [2023-02-09 16:50:22.101] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Starting task 0.0 in stage 15.0 (TID 9) (coke, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()]
[INFO ] [2023-02-09 16:50:22.102] [] [] [org.apache.spark.executor.Executor] [61] -[Running task 0.0 in stage 15.0 (TID 9)]
[INFO ] [2023-02-09 16:50:22.105] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks]
[INFO ] [2023-02-09 16:50:22.105] [] [] [o.apache.spark.storage.ShuffleBlockFetcherIterator] [61] -[Started 0 remote fetches in 0 ms]
[INFO ] [2023-02-09 16:50:22.109] [] [] [org.apache.spark.executor.Executor] [61] -[Finished task 0.0 in stage 15.0 (TID 9). 1376 bytes result sent to driver]
[INFO ] [2023-02-09 16:50:22.110] [] [] [org.apache.spark.scheduler.TaskSetManager] [61] -[Finished task 0.0 in stage 15.0 (TID 9) in 9 ms on coke (executor driver) (1/1)]
[INFO ] [2023-02-09 16:50:22.111] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Removed TaskSet 15.0, whose tasks have all completed, from pool ]
[INFO ] [2023-02-09 16:50:22.111] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[ResultStage 15 (treeAggregate at RowMatrix.scala:171) finished in 0.018 s]
[INFO ] [2023-02-09 16:50:22.112] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 7 is finished. Cancelling potential speculative or zombie tasks for this job]
[INFO ] [2023-02-09 16:50:22.112] [] [] [org.apache.spark.scheduler.TaskSchedulerImpl] [61] -[Killing all running tasks in stage 15: Stage finished]
[INFO ] [2023-02-09 16:50:22.112] [] [] [org.apache.spark.scheduler.DAGScheduler] [61] -[Job 7 finished: treeAggregate at RowMatrix.scala:171, took 0.023460 s]
[INFO ] [2023-02-09 16:50:22.113] [] [] [org.apache.spark.broadcast.TorrentBroadcast] [61] -[Destroying Broadcast(10) (from destroy at RowMatrix.scala:201)]
[WARN ] [2023-02-09 16:50:22.113] [] [] [o.a.s.mllib.stat.correlation.PearsonCorrelation] [73] -[Pearson correlation matrix contains NaN values.]
[INFO ] [2023-02-09 16:50:22.114] [] [] [org.apache.spark.storage.BlockManagerInfo] [61] -[Removed broadcast_10_piece0 on coke:12678 in memory (size: 167.0 B, free: 1712.4 MiB)]
